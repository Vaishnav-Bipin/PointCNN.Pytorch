nohup: ignoring input
Epoch: 1
Train_acc: 0.17366279069767443
Train_loss: 3.1794328689575195
Test_acc: 0.2091789667896679
Global_step: 1076
Epoch: 2
Train_acc: 0.21424418604651163
Train_loss: 2.9053540229797363
Test_acc: 0.21292666051660517
Global_step: 2151
Epoch: 3
Train_acc: 0.21659883720930231
Train_loss: 3.053745746612549
Test_acc: 0.21765452029520296
Global_step: 3226
Epoch: 4
Train_acc: 0.22055232558139534
Train_loss: 2.752049446105957
Test_acc: 0.2180581180811808
Global_step: 4301
Epoch: 5
Train_acc: 0.2229360465116279
Train_loss: 2.843386650085449
Test_acc: 0.2227859778597786
Global_step: 5376
Epoch: 6
Train_acc: 0.22796511627906976
Train_loss: 2.9917898178100586
Test_acc: 0.22664898523985239
Global_step: 6451
Epoch: 7
Train_acc: 0.23232558139534884
Train_loss: 2.7512471675872803
Test_acc: 0.2318380996309963
Global_step: 7526
nohup: ignoring input
Epoch: 8
Train_acc: 0.23677325581395348
Train_loss: 3.1706759929656982
Test_acc: 0.2370848708487085
Global_step: 8601
Epoch: 9
Train_acc: 0.24069767441860465
Train_loss: 3.0308837890625
Test_acc: 0.24348477859778597
Global_step: 9676
Epoch: 10
Train_acc: 0.2427906976744186
Train_loss: 2.571035861968994
Test_acc: 0.24290821033210333
Global_step: 10751
Epoch: 11
Train_acc: 0.24549418604651163
Train_loss: 2.59529447555542
Test_acc: 0.24440728782287824
Global_step: 11826
Epoch: 12
Train_acc: 0.24770348837209302
Train_loss: 2.9820196628570557
Test_acc: 0.24942343173431733
Global_step: 12901
Epoch: 13
Train_acc: 0.24979651162790698
Train_loss: 2.8166677951812744
Test_acc: 0.2472901291512915
Global_step: 13976
Epoch: 14
Train_acc: 0.24892441860465117
Train_loss: 2.9065208435058594
Test_acc: 0.24705950184501846
Global_step: 15051
Epoch: 15
Train_acc: 0.25261627906976747
Train_loss: 2.7193191051483154
Test_acc: 0.25126845018450183
Global_step: 16126
Epoch: 16
Train_acc: 0.2517151162790698
Train_loss: 2.7234244346618652
Test_acc: 0.25121079335793356
Global_step: 17201
Epoch: 17
Train_acc: 0.2544767441860465
Train_loss: 2.8397555351257324
Test_acc: 0.25795664206642066
Global_step: 18276
Epoch: 18
Train_acc: 0.25656976744186044
Train_loss: 2.808659791946411
Test_acc: 0.2557656826568266
Global_step: 19351
nohup: ignoring input
Epoch: 19
Train_acc: 0.2595639534883721
Train_loss: 2.89686918258667
Test_acc: 0.2608971402214022
Global_step: 20426
Epoch: 20
Train_acc: 0.26058139534883723
Train_loss: 2.6797361373901367
Test_acc: 0.2591674354243542
Global_step: 21501
Epoch: 21
Train_acc: 0.26063953488372094
Train_loss: 2.3119542598724365
Test_acc: 0.2642988929889299
Global_step: 22576
Epoch: 22
Train_acc: 0.26063953488372094
Train_loss: 3.0447590351104736
Test_acc: 0.26101245387453875
Global_step: 23651
Epoch: 23
Train_acc: 0.26308139534883723
Train_loss: 2.839153289794922
Test_acc: 0.2624538745387454
Global_step: 24726
Epoch: 24
Train_acc: 0.2645639534883721
Train_loss: 2.478128433227539
Test_acc: 0.2618773062730627
Global_step: 25801
Epoch: 25
Train_acc: 0.2677616279069767
Train_loss: 2.2506680488586426
Test_acc: 0.26718173431734316
Global_step: 26876
Epoch: 26
Train_acc: 0.2675
Train_loss: 3.036494731903076
Test_acc: 0.2597440036900369
Global_step: 27951
Epoch: 27
Train_acc: 0.26738372093023255
Train_loss: 2.7962491512298584
Test_acc: 0.2734086715867159
Global_step: 29026
Epoch: 28
Train_acc: 0.27072674418604653
Train_loss: 2.4924652576446533
Test_acc: 0.2666051660516605
Global_step: 30101
Epoch: 29
Train_acc: 0.27162790697674416
Train_loss: 2.7681796550750732
Test_acc: 0.272140221402214
Global_step: 31176
Epoch: 30
Train_acc: 0.272703488372093
Train_loss: 2.660844087600708
Test_acc: 0.26856549815498154
Global_step: 32251
Epoch: 31
Train_acc: 0.2760755813953488
Train_loss: 2.677457094192505
Test_acc: 0.2768104243542435
Global_step: 33326
Epoch: 32
Train_acc: 0.2761918604651163
Train_loss: 2.8405203819274902
Test_acc: 0.2775023062730627
Global_step: 34401
Epoch: 33
Train_acc: 0.2771220930232558
Train_loss: 2.6427500247955322
Test_acc: 0.2764068265682657
Global_step: 35476
Epoch: 34
Train_acc: 0.28063953488372095
Train_loss: 2.4733197689056396
Test_acc: 0.27848247232472323
Global_step: 36551
Epoch: 35
Train_acc: 0.28078488372093025
Train_loss: 2.2474911212921143
Test_acc: 0.27600322878228783
Global_step: 37626
Epoch: 36
Train_acc: 0.28412790697674417
Train_loss: 2.5657835006713867
Test_acc: 0.28148062730627305
Global_step: 38701
Epoch: 37
Train_acc: 0.2833139534883721
Train_loss: 2.914538860321045
Test_acc: 0.27900138376383765
Global_step: 39776
Epoch: 38
Train_acc: 0.2839825581395349
Train_loss: 2.723660707473755
Test_acc: 0.28551660516605165
Global_step: 40851
Epoch: 39
Train_acc: 0.2856395348837209
Train_loss: 2.4570279121398926
Test_acc: 0.28649677121771217
Global_step: 41926
Epoch: 40
Train_acc: 0.2863662790697674
Train_loss: 2.5941860675811768
Test_acc: 0.28303736162361626
Global_step: 43001
Epoch: 41
Train_acc: 0.28776162790697674
Train_loss: 2.517591714859009
Test_acc: 0.2866120848708487
Global_step: 44076
Epoch: 42
Train_acc: 0.2888953488372093
Train_loss: 2.254807472229004
Test_acc: 0.28378690036900367
Global_step: 45151
Epoch: 43
Train_acc: 0.28927325581395347
Train_loss: 2.7632384300231934
Test_acc: 0.2890913284132841
Global_step: 46226
Epoch: 44
Train_acc: 0.29040697674418603
Train_loss: 2.5554966926574707
Test_acc: 0.2890913284132841
Global_step: 47301
Epoch: 45
Train_acc: 0.2911046511627907
Train_loss: 2.6556966304779053
Test_acc: 0.29157057195571956
Global_step: 48376
Epoch: 46
Train_acc: 0.2919767441860465
Train_loss: 2.669872283935547
Test_acc: 0.2889760147601476
Global_step: 49451
Epoch: 47
Train_acc: 0.29125
Train_loss: 2.728693723678589
Test_acc: 0.2897832103321033
Global_step: 50526
Epoch: 48
Train_acc: 0.2951453488372093
Train_loss: 2.6327126026153564
Test_acc: 0.29295433579335795
Global_step: 51601
Epoch: 49
Train_acc: 0.2944767441860465
Train_loss: 2.6505753993988037
Test_acc: 0.28961023985239853
Global_step: 52676
Epoch: 50
Train_acc: 0.29505813953488375
Train_loss: 2.7456657886505127
Test_acc: 0.2904750922509225
Global_step: 53751
Epoch: 51
Train_acc: 0.2969767441860465
Train_loss: 2.8056962490081787
Test_acc: 0.291455258302583
Global_step: 54826
Epoch: 52
Train_acc: 0.2980232558139535
Train_loss: 2.8036062717437744
Test_acc: 0.2941651291512915
Global_step: 55901
Epoch: 53
Train_acc: 0.29921511627906977
Train_loss: 2.3705015182495117
Test_acc: 0.29664437269372695
Global_step: 56976
Epoch: 54
Train_acc: 0.29709302325581394
Train_loss: 2.378485918045044
Test_acc: 0.292320110701107
Global_step: 58051
Epoch: 55
Train_acc: 0.301453488372093
Train_loss: 2.285310983657837
Test_acc: 0.29560654981549817
Global_step: 59126
Epoch: 56
Train_acc: 0.3000581395348837
Train_loss: 2.6150569915771484
Test_acc: 0.3009109778597786
Global_step: 60201
Epoch: 57
Train_acc: 0.30104651162790697
Train_loss: 2.770097494125366
Test_acc: 0.29814345018450183
Global_step: 61276
Epoch: 58
Train_acc: 0.3006104651162791
Train_loss: 2.473823070526123
Test_acc: 0.29629843173431736
Global_step: 62351
Epoch: 59
Train_acc: 0.30279069767441863
Train_loss: 3.0139248371124268
Test_acc: 0.3003920664206642
Global_step: 63426
Epoch: 60
Train_acc: 0.305
Train_loss: 2.30015230178833
Test_acc: 0.29399215867158673
Global_step: 64501
Epoch: 61
Train_acc: 0.30375
Train_loss: 2.4858126640319824
Test_acc: 0.29773985239852396
Global_step: 65576
Epoch: 62
Train_acc: 0.3051453488372093
Train_loss: 2.522632598876953
Test_acc: 0.2958371771217712
Global_step: 66651
Epoch: 63
Train_acc: 0.30680232558139536
Train_loss: 2.713688850402832
Test_acc: 0.30016143911439114
Global_step: 67726
Epoch: 64
Train_acc: 0.30686046511627907
Train_loss: 3.2625210285186768
Test_acc: 0.30200645756457567
Global_step: 68801
Epoch: 65
Train_acc: 0.30770348837209305
Train_loss: 2.514904260635376
Test_acc: 0.3040821033210332
Global_step: 69876
Epoch: 66
Train_acc: 0.30883720930232555
Train_loss: 2.1807148456573486
Test_acc: 0.3027559963099631
Global_step: 70951
Epoch: 67
Train_acc: 0.30965116279069765
Train_loss: 2.5731308460235596
Test_acc: 0.3015452029520295
Global_step: 72026
Epoch: 68
Train_acc: 0.309796511627907
Train_loss: 2.696911334991455
Test_acc: 0.3081180811808118
Global_step: 73101
Epoch: 69
Train_acc: 0.3132558139534884
Train_loss: 2.392834424972534
Test_acc: 0.30183348708487084
Global_step: 74176
Epoch: 70
Train_acc: 0.3109593023255814
Train_loss: 2.1088411808013916
Test_acc: 0.30281365313653136
Global_step: 75251
Epoch: 71
Train_acc: 0.31380813953488373
Train_loss: 2.4339897632598877
Test_acc: 0.30454335793357934
Global_step: 76326
Epoch: 72
Train_acc: 0.31238372093023253
Train_loss: 2.65415358543396
Test_acc: 0.30904059040590404
Global_step: 77401
Epoch: 73
Train_acc: 0.31552325581395346
Train_loss: 2.5603487491607666
Test_acc: 0.3074838560885609
Global_step: 78476
Epoch: 74
Train_acc: 0.3167732558139535
Train_loss: 2.414936065673828
Test_acc: 0.30385147601476015
Global_step: 79551
nohup: ignoring input
Epoch: 75
Train_acc: 0.3149418604651163
Train_loss: 2.7734181880950928
Test_acc: 0.310539667896679
Global_step: 80626
Epoch: 76
Train_acc: 0.31511627906976747
Train_loss: 2.5961239337921143
Test_acc: 0.3110009225092251
Global_step: 81701
Epoch: 77
Train_acc: 0.31738372093023254
Train_loss: 2.9599244594573975
Test_acc: 0.31307656826568264
Global_step: 82776
Epoch: 78
Train_acc: 0.31973837209302325
Train_loss: 2.6880335807800293
Test_acc: 0.30886761992619927
Global_step: 83851
Epoch: 79
Train_acc: 0.31950581395348837
Train_loss: 2.641794204711914
Test_acc: 0.30823339483394835
Global_step: 84926
Epoch: 80
Train_acc: 0.32049418604651164
Train_loss: 2.6467413902282715
Test_acc: 0.3125
Global_step: 86001
Epoch: 81
Train_acc: 0.3191860465116279
Train_loss: 2.8432774543762207
Test_acc: 0.31123154981549817
Global_step: 87076
Epoch: 82
Train_acc: 0.3226162790697674
Train_loss: 2.758226156234741
Test_acc: 0.3169395756457565
Global_step: 88151
Epoch: 83
Train_acc: 0.3216279069767442
Train_loss: 2.535646915435791
Test_acc: 0.310770295202952
Global_step: 89226
Epoch: 84
Train_acc: 0.31965116279069766
Train_loss: 2.248967409133911
Test_acc: 0.30857933579335795
Global_step: 90301
Epoch: 85
Train_acc: 0.32325581395348835
Train_loss: 3.1708128452301025
Test_acc: 0.314460332103321
Global_step: 91376
Epoch: 86
Train_acc: 0.3231686046511628
Train_loss: 2.2916905879974365
Test_acc: 0.31198108856088563
Global_step: 92451
Epoch: 87
Train_acc: 0.32392441860465115
Train_loss: 2.1847574710845947
Test_acc: 0.3183233394833948
Global_step: 93526
Epoch: 88
Train_acc: 0.32526162790697677
Train_loss: 2.3308749198913574
Test_acc: 0.31267297047970477
Global_step: 94601
Epoch: 89
Train_acc: 0.3261627906976744
Train_loss: 2.5922577381134033
Test_acc: 0.31105857933579334
Global_step: 95676
Epoch: 90
Train_acc: 0.32497093023255813
Train_loss: 2.5819857120513916
Test_acc: 0.31226937269372695
Global_step: 96751
Epoch: 91
Train_acc: 0.3253197674418605
Train_loss: 2.2160003185272217
Test_acc: 0.3165359778597786
Global_step: 97826
Epoch: 92
Train_acc: 0.32915697674418604
Train_loss: 2.382402181625366
Test_acc: 0.3172278597785978
Global_step: 98901
Epoch: 93
Train_acc: 0.3288953488372093
Train_loss: 2.6271555423736572
Test_acc: 0.3104243542435424
Global_step: 99976
Epoch: 94
Train_acc: 0.3280232558139535
Train_loss: 2.7078640460968018
Test_acc: 0.3189575645756458
Global_step: 101051
Epoch: 95
Train_acc: 0.32968023255813955
Train_loss: 2.216679573059082
Test_acc: 0.31884225092250923
Global_step: 102126
Epoch: 96
Train_acc: 0.33223837209302326
Train_loss: 2.270920515060425
Test_acc: 0.3196494464944649
Global_step: 103201
Epoch: 97
Train_acc: 0.3311046511627907
Train_loss: 2.9189484119415283
Test_acc: 0.3193035055350554
Global_step: 104276
Epoch: 98
Train_acc: 0.32915697674418604
Train_loss: 2.533642292022705
Test_acc: 0.32045664206642066
Global_step: 105351
Epoch: 99
Train_acc: 0.33125
Train_loss: 2.2985050678253174
Test_acc: 0.3205719557195572
Global_step: 106426
Epoch: 100
Train_acc: 0.33247093023255814
Train_loss: 2.7199409008026123
Test_acc: 0.31405673431734316
Global_step: 107501
Epoch: 101
Train_acc: 0.3325
Train_loss: 2.1904983520507812
Test_acc: 0.321609778597786
Global_step: 108576
Epoch: 102
Train_acc: 0.33325581395348836
Train_loss: 2.663161277770996
Test_acc: 0.3168819188191882
Global_step: 109651
Epoch: 103
Train_acc: 0.3329651162790698
Train_loss: 2.0785059928894043
Test_acc: 0.32011070110701106
Global_step: 110726
Epoch: 104
Train_acc: 0.33502906976744184
Train_loss: 2.4694573879241943
Test_acc: 0.31780442804428044
Global_step: 111801
Epoch: 105
Train_acc: 0.33235465116279067
Train_loss: 2.8627567291259766
Test_acc: 0.31745848708487084
Global_step: 112876
Epoch: 106
Train_acc: 0.3350581395348837
Train_loss: 2.655322790145874
Test_acc: 0.3172855166051661
Global_step: 113951
Epoch: 107
Train_acc: 0.33578488372093024
Train_loss: 2.328298807144165
Test_acc: 0.32483856088560886
Global_step: 115026
Epoch: 108
Train_acc: 0.3353488372093023
Train_loss: 2.446474313735962
Test_acc: 0.32835562730627305
Global_step: 116101
Epoch: 109
Train_acc: 0.33997093023255814
Train_loss: 2.2282652854919434
Test_acc: 0.324434963099631
Global_step: 117176
Epoch: 110
Train_acc: 0.33909883720930234
Train_loss: 2.6755335330963135
Test_acc: 0.324434963099631
Global_step: 118251
Epoch: 111
Train_acc: 0.33723837209302326
Train_loss: 2.607527017593384
Test_acc: 0.32218634686346864
Global_step: 119326
nohup: ignoring input
Epoch: 112
Train_acc: 0.33994186046511626
Train_loss: 2.4719901084899902
Test_acc: 0.3227629151291513
Global_step: 120401
Epoch: 113
Train_acc: 0.33805232558139536
Train_loss: 2.4781723022460938
Test_acc: 0.32697186346863466
Global_step: 121476
Epoch: 114
Train_acc: 0.34081395348837207
Train_loss: 2.7759833335876465
Test_acc: 0.32420433579335795
Global_step: 122551
Epoch: 115
Train_acc: 0.3380232558139535
Train_loss: 2.6754209995269775
Test_acc: 0.3212638376383764
Global_step: 123626
Epoch: 116
Train_acc: 0.3384593023255814
Train_loss: 2.7283241748809814
Test_acc: 0.32414667896678967
Global_step: 124701
Epoch: 117
Train_acc: 0.34005813953488373
Train_loss: 3.0944509506225586
Test_acc: 0.324434963099631
Global_step: 125776
Epoch: 118
Train_acc: 0.3402325581395349
Train_loss: 2.21134614944458
Test_acc: 0.32316651291512916
Global_step: 126851
Epoch: 119
Train_acc: 0.34136627906976746
Train_loss: 2.2986557483673096
Test_acc: 0.3259340405904059
Global_step: 127926
Epoch: 120
Train_acc: 0.342296511627907
Train_loss: 2.897067070007324
Test_acc: 0.32316651291512916
Global_step: 129001
Epoch: 121
Train_acc: 0.3437790697674419
Train_loss: 2.0427937507629395
Test_acc: 0.32455027675276754
Global_step: 130076
Epoch: 122
Train_acc: 0.3461627906976744
Train_loss: 2.193438768386841
Test_acc: 0.32449261992619927
Global_step: 131151
Epoch: 123
Train_acc: 0.342906976744186
Train_loss: 2.4128341674804688
Test_acc: 0.3281826568265683
Global_step: 132226
Epoch: 124
Train_acc: 0.34659883720930235
Train_loss: 2.562134265899658
Test_acc: 0.3257034132841328
Global_step: 133301
Epoch: 125
Train_acc: 0.34494186046511627
Train_loss: 2.5348284244537354
Test_acc: 0.3266259225092251
Global_step: 134376
Epoch: 126
Train_acc: 0.3447093023255814
Train_loss: 2.0808985233306885
Test_acc: 0.32731780442804426
Global_step: 135451
Epoch: 127
Train_acc: 0.34473837209302327
Train_loss: 1.761692762374878
Test_acc: 0.3236854243542435
Global_step: 136526
Epoch: 128
Train_acc: 0.345406976744186
Train_loss: 2.8631787300109863
Test_acc: 0.3238007380073801
Global_step: 137601
Epoch: 129
Train_acc: 0.34494186046511627
Train_loss: 2.347606897354126
Test_acc: 0.32483856088560886
Global_step: 138676
Epoch: 130
Train_acc: 0.3451453488372093
Train_loss: 2.4125494956970215
Test_acc: 0.3301429889298893
Global_step: 139751
Epoch: 131
Train_acc: 0.3456104651162791
Train_loss: 2.550090789794922
Test_acc: 0.3267412361623616
Global_step: 140826
Epoch: 132
Train_acc: 0.3470348837209302
Train_loss: 2.4066781997680664
Test_acc: 0.3274331180811808
Global_step: 141901
Epoch: 133
Train_acc: 0.35017441860465115
Train_loss: 2.1727893352508545
Test_acc: 0.3278367158671587
Global_step: 142976
Epoch: 134
Train_acc: 0.3494186046511628
Train_loss: 2.2272074222564697
Test_acc: 0.3257034132841328
Global_step: 144051
Epoch: 135
Train_acc: 0.3499418604651163
Train_loss: 2.530613422393799
Test_acc: 0.33025830258302585
Global_step: 145126
Epoch: 136
Train_acc: 0.35104651162790695
Train_loss: 2.51792049407959
Test_acc: 0.33123846863468637
Global_step: 146201
Epoch: 137
Train_acc: 0.3505232558139535
Train_loss: 2.159820795059204
Test_acc: 0.33123846863468637
Global_step: 147276
Epoch: 138
Train_acc: 0.3506395348837209
Train_loss: 2.439143657684326
Test_acc: 0.3278367158671587
Global_step: 148351
Epoch: 139
Train_acc: 0.35020348837209303
Train_loss: 2.937821626663208
Test_acc: 0.32922047970479706
Global_step: 149426
Epoch: 140
Train_acc: 0.35255813953488374
Train_loss: 2.5527031421661377
Test_acc: 0.3304889298892989
Global_step: 150501
Epoch: 141
Train_acc: 0.3520348837209302
Train_loss: 2.4108660221099854
Test_acc: 0.32633763837638374
Global_step: 151576
Epoch: 142
Train_acc: 0.3556104651162791
Train_loss: 2.6140365600585938
Test_acc: 0.33002767527675275
Global_step: 152651
Epoch: 143
Train_acc: 0.35101744186046513
Train_loss: 2.650438070297241
Test_acc: 0.33406365313653136
Global_step: 153726
Epoch: 144
Train_acc: 0.35505813953488374
Train_loss: 2.3448874950408936
Test_acc: 0.33337177121771217
Global_step: 154801
Epoch: 145
Train_acc: 0.3536627906976744
Train_loss: 2.129894971847534
Test_acc: 0.3278367158671587
Global_step: 155876
Epoch: 146
Train_acc: 0.35508720930232557
Train_loss: 2.4708917140960693
Test_acc: 0.338330258302583
Global_step: 156951
Epoch: 147
Train_acc: 0.3529651162790698
Train_loss: 2.6559650897979736
Test_acc: 0.3296240774907749
Global_step: 158026
Epoch: 148
Train_acc: 0.355
Train_loss: 2.490121841430664
Test_acc: 0.3315267527675277
Global_step: 159101
Epoch: 149
Train_acc: 0.3549418604651163
Train_loss: 2.2447454929351807
Test_acc: 0.3301429889298893
Global_step: 160176
Epoch: 150
Train_acc: 0.3561627906976744
Train_loss: 2.7922937870025635
Test_acc: 0.33538976014760147
Global_step: 161251
Epoch: 151
Train_acc: 0.35869186046511625
Train_loss: 2.2060787677764893
Test_acc: 0.33169972324723246
Global_step: 162326
Epoch: 152
Train_acc: 0.3590697674418605
Train_loss: 2.4463086128234863
Test_acc: 0.33377536900369004
Global_step: 163401
Epoch: 153
Train_acc: 0.35691860465116276
Train_loss: 2.2993686199188232
Test_acc: 0.3348131918819188
Global_step: 164476
Epoch: 154
Train_acc: 0.35915697674418606
Train_loss: 2.3682773113250732
Test_acc: 0.33360239852398527
Global_step: 165551
Epoch: 155
Train_acc: 0.35869186046511625
Train_loss: 2.456787109375
Test_acc: 0.3336600553505535
Global_step: 166626
Epoch: 156
Train_acc: 0.3590697674418605
Train_loss: 2.267460584640503
Test_acc: 0.33648523985239853
Global_step: 167701
Epoch: 157
Train_acc: 0.36093023255813955
Train_loss: 2.8164520263671875
Test_acc: 0.33504381918819187
Global_step: 168776
Epoch: 158
Train_acc: 0.35973837209302323
Train_loss: 2.404279947280884
Test_acc: 0.33613929889298894
Global_step: 169851
Epoch: 159
Train_acc: 0.3624418604651163
Train_loss: 2.3685832023620605
Test_acc: 0.3311231549815498
Global_step: 170926
Epoch: 160
Train_acc: 0.36183139534883724
Train_loss: 2.7793588638305664
Test_acc: 0.3371771217712177
Global_step: 172001
Epoch: 161
Train_acc: 0.3627906976744186
Train_loss: 2.549715280532837
Test_acc: 0.338330258302583
Global_step: 173076
Epoch: 162
Train_acc: 0.3633139534883721
Train_loss: 2.5877230167388916
Test_acc: 0.33781134686346864
Global_step: 174151
Epoch: 163
Train_acc: 0.3639825581395349
Train_loss: 2.5930325984954834
Test_acc: 0.3326222324723247
Global_step: 175226
Epoch: 164
Train_acc: 0.36296511627906974
Train_loss: 2.2257626056671143
Test_acc: 0.3395410516605166
Global_step: 176301
Epoch: 165
Train_acc: 0.36415697674418607
Train_loss: 2.1167962551116943
Test_acc: 0.337234778597786
Global_step: 177376
Epoch: 166
Train_acc: 0.36511627906976746
Train_loss: 2.3481674194335938
Test_acc: 0.33446725092250923
Global_step: 178451
Epoch: 167
Train_acc: 0.3665406976744186
Train_loss: 2.1530110836029053
Test_acc: 0.34253920664206644
Global_step: 179526
Epoch: 168
Train_acc: 0.3648837209302326
Train_loss: 2.302537441253662
Test_acc: 0.3386761992619926
Global_step: 180601
Epoch: 169
Train_acc: 0.3649127906976744
Train_loss: 2.3364756107330322
Test_acc: 0.33608164206642066
Global_step: 181676
Epoch: 170
Train_acc: 0.36619186046511626
Train_loss: 2.228194236755371
Test_acc: 0.3314690959409594
Global_step: 182751
Epoch: 171
Train_acc: 0.3656976744186046
Train_loss: 2.408324956893921
Test_acc: 0.3369464944649446
Global_step: 183826
Epoch: 172
Train_acc: 0.3675872093023256
Train_loss: 2.7463161945343018
Test_acc: 0.3356780442804428
Global_step: 184901
Epoch: 173
Train_acc: 0.36619186046511626
Train_loss: 2.1607441902160645
Test_acc: 0.3349861623616236
Global_step: 185976
Epoch: 174
Train_acc: 0.3692151162790698
Train_loss: 1.7780849933624268
Test_acc: 0.3366582103321033
Global_step: 187051
Epoch: 175
Train_acc: 0.36790697674418604
Train_loss: 2.418951988220215
Test_acc: 0.3353321033210332
Global_step: 188126
Epoch: 176
Train_acc: 0.369796511627907
Train_loss: 2.6521084308624268
Test_acc: 0.3305465867158672
Global_step: 189201
Epoch: 177
Train_acc: 0.3698255813953488
Train_loss: 2.3019297122955322
Test_acc: 0.3393104243542435
Global_step: 190276
Epoch: 178
Train_acc: 0.3691860465116279
Train_loss: 2.248398542404175
Test_acc: 0.341789667896679
Global_step: 191351
Epoch: 179
Train_acc: 0.37119186046511626
Train_loss: 2.4545750617980957
Test_acc: 0.34351937269372695
Global_step: 192426
Epoch: 180
Train_acc: 0.37040697674418605
Train_loss: 2.3051555156707764
Test_acc: 0.3360239852398524
Global_step: 193501
Epoch: 181
Train_acc: 0.3688081395348837
Train_loss: 2.231322765350342
Test_acc: 0.33538976014760147
Global_step: 194576
Epoch: 182
Train_acc: 0.3724127906976744
Train_loss: 2.0950891971588135
Test_acc: 0.3440959409594096
Global_step: 195651
Epoch: 183
Train_acc: 0.3724127906976744
Train_loss: 2.1804163455963135
Test_acc: 0.3370618081180812
Global_step: 196726
Epoch: 184
Train_acc: 0.37055232558139534
Train_loss: 2.1472251415252686
Test_acc: 0.34184732472324725
Global_step: 197801
Epoch: 185
Train_acc: 0.3715406976744186
Train_loss: 2.4408340454101562
Test_acc: 0.3393104243542435
Global_step: 198876
